{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Six: Wide and Deep Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Austin Chen, Luke Hansen, Oscar Vallner*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation and Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the 6th Lab Assignment, we will be using the \"Diabetes 130-US hospitals of years 1999-2008\" dataset, downloaded from the UCI Machine Learning Repository. This dataset has been prepared for usage in analyzing medical factors related to hospital readmission for patients with diabetes. The dataset represents ten years worth of clinical care data from 130 hospitals in the United States, as well as integrated delivery networks. In order for an entry to qualify for the dataset, it must satisfy the following requirements:\n",
    "\n",
    "1. It must be a hospital admission\n",
    "2. The admission must be diabetic related\n",
    "3. The length of the stay must be more than 1 day but less than 2 weeks.\n",
    "4. Laboratory tests must have been performed on the patient\n",
    "5. Medications must have been administered or prescribed.\n",
    "\n",
    "The dataset's features comprise of a mix of nominal and numeric datatypes. The features span a multitude of patient information categories such as race, gender, age, weight, and time spent in hospital. Some of the more specific features include information such as medications administered (miglitol, metformin, tolazamide, etc) and number of lab procedures. \n",
    "\n",
    "The features and content of this dataset can provide extremely important information for the healthcare industry, for various reasons. First and foremost, a classification model that can accurately predict whether a diabetic inpatient will return to the hospital has several implications in itself. On the medical side, knowing that a patient is at risk for rehospitalization, given a patient's specific attributes, can help doctors and physicians modify their treatment methodology to minimize the chance of rehospitalization. A similar concept applies for the patients themselves; patients who can know they may be at risk for rehospitalization can take extra precautions once they are discharged in an attempt to prevent further emergencies. And finally, if hospital administrators know that a certain number of patients will be readmitted, they could use this information in order to better plan room reservations, medical supply projections, and further logistical planning. Though it is difficult to plan resources for hospitals due to their hectic nature, having the information is still there nonetheless, and provides more options. In any case, the business applications are wide and deep no matter the stakeholder.\n",
    "\n",
    "With the aforementioned data, we plan to construct a classifier that will predict whether or not a patient will be rehospitalized within 30 days after discharge.\n",
    "\n",
    "However, we must highlight an important issue with our classification task. The original dataset creates three distinct class boundaries for hospital readmittance:\n",
    "\n",
    "1. NO: No record of readmission\n",
    "2. &lt;30: If the patient was readmitted in less than 30 days.\n",
    "3. &gt;30: If the patient was readmitted in more than 30 days.\n",
    "\n",
    "For the sake of our business case, we believe it would be far more feasible to narrow the scope to a binary classification. Instead of the three distinct classes seen above, a simplification could prove more pratical and informative:\n",
    "\n",
    "1. NO: No record of readmission\n",
    "2. &lt;30: If the patient was readmitted in less than 30 days.\n",
    "\n",
    "We have decided to eliminate the third type above (>30 days) for a number of reasons. First, it is important to reiterate that one of our primary business cases is to help medical professionals improve their treatment methodologies on diabetic hospital patients. Once a patient has been released for more than 30 days, the more difficult it becomes to blame any rehospitalizations on the aspects of the procedure itself. Pinpointing reasons for rehopsitalization becomes far more nebulous once a significant amount of time has passed since original hospitalization. There could be several extenuating external circumstances that contribute to a rehospitalization of a patient independent of the hospital's treatment. Furthermore, limiting the scope to a binary classification can greatly enhance our ability to choose the most appropriate evaluation method. For an industry as important as healthcare, especially where human life is at risk, we believe that a simpler classification, with better evaluation practices and better performance, is more deployable than a multi-class problem with lower performance. Because the mere concept of emergency hospitalization bears the risk of human mortality, we would want to achieve an accuracy of at least 95+%. **However, as we will discuss later, pure accuracy will not be our primary evaluation metric.**\n",
    "\n",
    "With more time, we can continue to refine our classification model to accomodate more classes. With regards to our specific dataset, we would require consultation with a domain expert in order to evaluate the extenuating circumstances that contribute to rehospitalization past 30 days. \n",
    "\n",
    "---\n",
    "\n",
    "Link to dataset: http://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008#\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.2 Class Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "Here is a full guide to the features found in our dataset. A more comprehensive feature guide can be found here: https://www.hindawi.com/journals/bmri/2014/781670/tab1/\n",
    "\n",
    "<br> </br>\n",
    "\n",
    "| No. Feature     | Feature Name  | Feature Type    | Description     |\n",
    "| :-------------: |:-------------:| :-------------: | :-------------: |\n",
    "| ~~1~~ | ~~encounter_id~~ | ~~Numeric~~ | *Removed from dataset for model* |\n",
    "| ~~2~~ | ~~patient_nbr~~ | ~~Numeric~~ | *Removed from dataset for model* |\n",
    "| 3 | race | Nominal | Race: Caucasian, Asian, Hispanic, etc. | \n",
    "| 4 | gender | Nominal| Gender: male, female, unknown/invalid |\n",
    "| 5 | age | Nominal | Age ranges in 10-year intervals: [0, 10), [10, 20) |\n",
    "| ~~6~~ | ~~weight~~ | ~~Numeric~~ | *Removed from dataset for model* |\n",
    "| 7 | admission_type_id | Nominal | Integer ientifier. Ex. Emergency, elective, etc. |\n",
    "| 8 | discharge_disposition_id | Nominal | Integer identifier. Ex. Discharged to home, expired, etc. |\n",
    "| 9 | admission_source_id | Nominal | Integer identifier |\n",
    "| 10 | time_in_hospital | Numeric | Integer number of days spent in hospital |\n",
    "| ~~11~~ | ~~payer_code~~ | ~~Nominal~~ | *Removed from dataset for model* |\n",
    "| ~~12~~ | ~~medical_specialty~~ | ~~Nominal~~ | *Removed from dataset for model* |\n",
    "| 13 | num_lab_procedures | Numeric | Number of lab tests performed during admission |\n",
    "| 14 | num_procedures | Numeric | Number of other procedures performed during admission |\n",
    "| 15 | num_medications | Numeric | Number of distinct medications administered during encounter |\n",
    "| 16 | num_outpatient | Number | Number of outpatient visits of the patient in the year preceding the encounter |\n",
    "| 17 | number_emergency | Number | Number of emergency visits of the patient in the year preceding the encounter |\n",
    "| 18 | number_inpatient | Number | Number of impatient visits of the patient in the year preceding the encounter |\n",
    "| 19 | diag_1 | Nominal | Primary diagnosis |\n",
    "| 20 | diag_2 | Nominal | Secondary diagnosis |\n",
    "| 21 | diag_3 | Nominal| Any additional secondary diagnosis |\n",
    "| 22 | number_diagnoses | Numeric | Number of diagnoses |\n",
    "| 23 | max_glu_serum | Nominal |  Result for glucose serum test. Represented by a range of values. |\n",
    "| 24 | A1Cresult | Nominal | Result for A1c test. Represented by a arange of values. |\n",
    "| 25-48 | Medications | Nominal | 24 features for different medications |\n",
    "| 49 | change | Nominal | Whether there was a change in diabetic medications. |\n",
    "| 50 | diabetesMed | Nominal | Indicates whether any diabetic medication was prescribed. |\n",
    "| 51 | Readmitted | Nominal | Whether patient was readmitted. \"No\" or \"less than 30 days\". |\n",
    "\n",
    "<br> </br>\n",
    "\n",
    "Though we removed some features such as encounter_id and patient_nbr because they don't contribute any relevant information to our classification dataset, we also decided to remove a few other features that actually have conceptual significance to the dataset. For example, the weight attribute has many potential ties to qualifying overall health. However, 97% of the weight data was missing, and imputing 97% of the data for a category is not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin our data preparation by reading in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital    ...     citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1    ...              No      No                   No   \n",
       "1                 3    ...              No      Up                   No   \n",
       "2                 2    ...              No      No                   No   \n",
       "3                 2    ...              No      Up                   No   \n",
       "4                 1    ...              No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/diabetic_data.csv', encoding = 'latin1',low_memory=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the most important aspect of our data preparation is to narrow down our classification problem to binary classification, as we discussed above. We will be dropping all entries in which patients were readmitted over 30 days past their initial discharge. We will be changing all instances of \"NO\" (no readmittance) to 0 and all instances of \"&lt;30\" to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.readmitted[df.readmitted == 'NO' ] = 0\n",
    "df.readmitted[df.readmitted == '<30' ] = 1\n",
    "df = df.drop(df[df.readmitted == '>30'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will drop all features that are unnecessary for our classification model. Furthermore, we will be dropping entries in which there is unimputable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.drop(['encounter_id', 'patient_nbr', 'weight', 'payer_code', 'medical_specialty'], axis=1, inplace=True)\n",
    "df.dropna(axis=1, how='all')\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['readmitted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we must encode all the categorical features as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>glyburide-metformin_int</th>\n",
       "      <th>glipizide-metformin_int</th>\n",
       "      <th>glimepiride-pioglitazone_int</th>\n",
       "      <th>metformin-rosiglitazone_int</th>\n",
       "      <th>metformin-pioglitazone_int</th>\n",
       "      <th>change_int</th>\n",
       "      <th>diabetesMed_int</th>\n",
       "      <th>admission_type_id_int</th>\n",
       "      <th>discharge_disposition_id_int</th>\n",
       "      <th>admission_source_id_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47721</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.114867</td>\n",
       "      <td>0.471708</td>\n",
       "      <td>-0.225250</td>\n",
       "      <td>-1.059302</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98631</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[90-100)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.450195</td>\n",
       "      <td>-0.187521</td>\n",
       "      <td>-0.225250</td>\n",
       "      <td>-0.582235</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55025</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.114867</td>\n",
       "      <td>-0.897461</td>\n",
       "      <td>-0.225250</td>\n",
       "      <td>-0.343702</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24599</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.450195</td>\n",
       "      <td>-0.035392</td>\n",
       "      <td>-0.805627</td>\n",
       "      <td>-0.105168</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70940</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.785524</td>\n",
       "      <td>1.942297</td>\n",
       "      <td>-0.805627</td>\n",
       "      <td>0.491166</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  race  gender       age  admission_type_id  \\\n",
       "47721        Caucasian    Male   [80-90)                  1   \n",
       "98631        Caucasian  Female  [90-100)                  3   \n",
       "55025         Hispanic  Female   [70-80)                  2   \n",
       "24599        Caucasian    Male   [30-40)                  1   \n",
       "70940  AfricanAmerican    Male   [70-80)                  1   \n",
       "\n",
       "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "47721                         3                    7         -0.114867   \n",
       "98631                         1                    1         -0.450195   \n",
       "55025                         5                    7         -0.114867   \n",
       "24599                         1                    6         -0.450195   \n",
       "70940                         2                    7         -0.785524   \n",
       "\n",
       "       num_lab_procedures  num_procedures  num_medications  \\\n",
       "47721            0.471708       -0.225250        -1.059302   \n",
       "98631           -0.187521       -0.225250        -0.582235   \n",
       "55025           -0.897461       -0.225250        -0.343702   \n",
       "24599           -0.035392       -0.805627        -0.105168   \n",
       "70940            1.942297       -0.805627         0.491166   \n",
       "\n",
       "                ...            glyburide-metformin_int  \\\n",
       "47721           ...                                  1   \n",
       "98631           ...                                  1   \n",
       "55025           ...                                  1   \n",
       "24599           ...                                  1   \n",
       "70940           ...                                  1   \n",
       "\n",
       "       glipizide-metformin_int  glimepiride-pioglitazone_int  \\\n",
       "47721                        0                             0   \n",
       "98631                        0                             0   \n",
       "55025                        0                             0   \n",
       "24599                        0                             0   \n",
       "70940                        0                             0   \n",
       "\n",
       "      metformin-rosiglitazone_int metformin-pioglitazone_int change_int  \\\n",
       "47721                           0                          0          1   \n",
       "98631                           0                          0          0   \n",
       "55025                           0                          0          0   \n",
       "24599                           0                          0          1   \n",
       "70940                           0                          0          1   \n",
       "\n",
       "       diabetesMed_int admission_type_id_int discharge_disposition_id_int  \\\n",
       "47721                0                     1                            3   \n",
       "98631                1                     3                            1   \n",
       "55025                1                     2                            5   \n",
       "24599                1                     1                            1   \n",
       "70940                0                     1                            2   \n",
       "\n",
       "      admission_source_id_int  \n",
       "47721                       7  \n",
       "98631                       1  \n",
       "55025                       7  \n",
       "24599                       6  \n",
       "70940                       7  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "int_categorical_headers = [\n",
    "'admission_type_id',\n",
    "'discharge_disposition_id',\n",
    "'admission_source_id',\n",
    "]\n",
    "numeric_headers = [\n",
    "    \"time_in_hospital\", \n",
    "    \"num_lab_procedures\", \n",
    "    \"num_procedures\", \n",
    "    \"num_medications\", \n",
    "    \"number_outpatient\", \n",
    "    \"number_emergency\", \n",
    "    \"number_inpatient\", \n",
    "    \"number_diagnoses\",\n",
    "]\n",
    "categorical_headers = [\n",
    " 'diag_3',\n",
    " 'diag_2',\n",
    " 'diag_1',\n",
    " 'race',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'max_glu_serum',\n",
    " 'A1Cresult',\n",
    " 'metformin',\n",
    " 'repaglinide',\n",
    " 'nateglinide',\n",
    " 'chlorpropamide',\n",
    " 'glimepiride',\n",
    " 'acetohexamide',\n",
    " 'glipizide',\n",
    " 'glyburide',\n",
    " 'tolbutamide',\n",
    " 'pioglitazone',\n",
    " 'rosiglitazone',\n",
    " 'acarbose',\n",
    " 'miglitol',\n",
    " 'troglitazone',\n",
    " 'tolazamide',\n",
    " 'examide',\n",
    " 'citoglipton',\n",
    " 'insulin',\n",
    " 'glyburide-metformin',\n",
    " 'glipizide-metformin',\n",
    " 'glimepiride-pioglitazone',\n",
    " 'metformin-rosiglitazone',\n",
    " 'metformin-pioglitazone',\n",
    " 'change',\n",
    " 'diabetesMed']\n",
    "\n",
    "df_train.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.reset_index()\n",
    "\n",
    "df_test.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "df_test.reset_index()\n",
    "\n",
    "encoders = dict()\n",
    "\n",
    "for col in categorical_headers:\n",
    "    df[col] = df[col].str.strip()\n",
    "    df_train[col] = df_train[col].str.strip()\n",
    "    df_test[col] = df_test[col].str.strip()\n",
    "    \n",
    "\n",
    "    encoders[col] = LabelEncoder()\n",
    "    df[col+'_int'] = encoders[col].fit_transform(df[col])\n",
    "    df_train[col+'_int'] = encoders[col].transform(df_train[col])\n",
    "    df_test[col+'_int'] = encoders[col].transform(df_test[col])\n",
    "    \n",
    "    \n",
    "    \n",
    "for col in int_categorical_headers:\n",
    "    df[col+'_int'] = df[col]\n",
    "    df_train[col+'_int'] = df_train[col]\n",
    "    df_test[col+'_int'] = df_test[col]\n",
    "\n",
    "for col in numeric_headers:\n",
    "    df_train[col] = df_train[col].astype(np.float)\n",
    "    df_test[col] = df_test[col].astype(np.float)\n",
    "    df[col] = df[col].astype(np.float)\n",
    "    ss = StandardScaler()\n",
    "    df[col] = ss.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    df_train[col] = ss.transform(df_train[col].values.reshape(-1, 1))\n",
    "    df_test[col] = ss.transform(df_test[col].values.reshape(-1, 1))\n",
    "\n",
    "    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Cross-product Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at all the useful features in our dataset, we need to find features that can be combined into cross-product features for the purpose of memorization techniques in wide networks. Unfortunately, most of the medications and illnesses in the dataset require extreme domain knowledge, outside our realm of expertise as computer science undergraduates. Despite our lack of knowledge in the medical domain, we are still left with a few options that we can logically group together with common intuition in order to discover and create new features. These include:\n",
    "\n",
    "- [race, gender]: Race and gender may not be the deciding factor in our model's predictions. However, these two factors are intuitive and could potentially have correlations to different classification outcomes. Furthermore, race and gender cross-products make conceptual sense because certain race-gender combinations can sometimes have varying correlations to diabetic status. This could potentially be due to genetics and socioeconomic factors.\n",
    "\n",
    "- [age, diag_1]: Age and the patient's primary diagnosis are two other features that seem like they could be logiically grouped together. Crossing age with diagnosis may give more importance to a patient's age when determining how resilient they are to a certain illness and how that impacts their potential readmittance to the hospital. It is clear that in most circumstances, patients with a more advanced age might not react as well as a young adult, given the same illness.\n",
    "\n",
    "- [gender, diag_1]: Similar to the reasoning to age and primary diagnosis, it might be useful explore a gender-diagnosis cross-product feature. There may be primary diagnoses that vary by each gender.\n",
    "\n",
    "Though we have labelled instances of Cross-product features we would like to experiment, we thought it might also be worthwhile to mention a cross-product feature type that we would not want to experiment with. In particular, we do not think it would be wise to create cross-product features of the 24 different medications. Though it may be tempting to want to see how different combinations medications might correlate with one another, we simply do not have the domain expertise to authoritatively determine whether two medications may be mixed with each other. If we haphazardly generate cross-product features of two incompatible drugs, it would deviate from a realistic model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In determining the most important evaluation metric, it is important to reiterate the business case with our classification model. As we stated before, our binary classification problem aims to let doctors and patients know whether the patient is at risk for a hospital readmission within 30 days of discharge. Given that information, we strongly believe that it is of the utmost importance to reduce the number of false-negatives. In the context of our classification problem, a false-negative is would entail classifying a patient as a \"NO\" admittance, when they in truth, are at risk for return. Telling a patient that they have nothing to worry about, only to be hospitalized later, can be damaging to all stakeholders at hand. The patient might be dissapointed because they could have taken more precautionary measures despite not being told to, and the doctor's credibility would be damaged. It would be better to overprepare a discharged patient for the worst-case scenario by giving them a false-positive diagnosis.\n",
    "\n",
    "Given the contextual analysis above of our business case, we believe that the most appropriate evaluation metric for our model would be a Recall scoring model. We have decided to use Recall as our scoring metric because it is equally important whether or not the model's predictions are true-positive or true-negative, but also necessary to penalize the model for giving false-negatives that could underprepare the patient for planning their future health once they are discharged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Cross Validation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAD7CAYAAABdXO4CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2522fcf4fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "uniq, label = np.unique(df['readmitted'], return_inverse=True)\n",
    "\n",
    "plt.pie(np.bincount(label), labels=uniq, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Class Distribution:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at our class distribution visualization above, we can tell that we have a large class imbalance. 82.8% of our entries consist of patients who were not readmitted, while 17.2% of our dataset was readmitted. Because we have two unbalanced classes, it is statistically necessary to use a Stratified Split to ensure that each fold has an equal representation of the under-represented class. Because we only have around ~40,000 instances in our training set, compared to the tens of millions of diabetic patients in the United States, it makes sense to perform our cross-validation using a k-folding method. Due to the size limitation of our dataset when compared to the population numbers, we need to maximize the number of instances in each iteration of k-fold. A k = 10 fold cross-validation will utilize 90% of the data in each iteration. For the reasons mentioned above, we believe a 10-fold stratified cross validation will maximize the generalization performance of our trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our classification model, we will be experimenting with different implementations of neural networks. With our wide network, we will be implementing the cross-product features that we discussed above. For our deep network, we will be experimenting with different numbers of network layers. We will then integrate both wide and deep network architectures into one network and then experiment with different network architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Wide and Deep Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first start by creating a standard combined wide and deep network implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_numeric_headers = numeric_headers + int_categorical_headers\n",
    "categorical_headers_ints = [x+'_int' for x in categorical_headers]\n",
    "df_num =  df[numeric_headers].values\n",
    "X_train_num =  df_train[master_numeric_headers].values\n",
    "X_test_num =  df_test[master_numeric_headers].values\n",
    "y_train = df_train['readmitted'].values.astype(np.int)\n",
    "y_test = df_test['readmitted'].values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross columns for later. Declare them now in case a cell needs to \n",
    "# be rerun, eliminating single cell dependencies\n",
    "\n",
    "cross_columns = [['gender','race'],\n",
    "                 ['age', 'diag_1'],\n",
    "                ['gender', 'diag_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Configuration Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47677/47677 [==============================] - 29s - loss: 0.4236 - acc: 0.8342    \n",
      "Epoch 2/5\n",
      "47677/47677 [==============================] - 27s - loss: 0.4048 - acc: 0.8376    \n",
      "Epoch 3/5\n",
      "47677/47677 [==============================] - 27s - loss: 0.3969 - acc: 0.8389    \n",
      "Epoch 4/5\n",
      "47677/47677 [==============================] - 27s - loss: 0.3912 - acc: 0.8395    \n",
      "Epoch 5/5\n",
      "47677/47677 [==============================] - 27s - loss: 0.3866 - acc: 0.8408    \n",
      "Epoch 1/5\n",
      "47678/47678 [==============================] - 29s - loss: 0.4249 - acc: 0.8332    \n",
      "Epoch 2/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.4072 - acc: 0.8361    \n",
      "Epoch 3/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3996 - acc: 0.8375    \n",
      "Epoch 4/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3937 - acc: 0.8387    \n",
      "Epoch 5/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3892 - acc: 0.8396    \n",
      "Epoch 1/5\n",
      "47678/47678 [==============================] - 29s - loss: 0.4228 - acc: 0.8341    \n",
      "Epoch 2/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.4054 - acc: 0.8371    \n",
      "Epoch 3/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3974 - acc: 0.8384    \n",
      "Epoch 4/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3916 - acc: 0.8396    \n",
      "Epoch 5/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3872 - acc: 0.8401    \n",
      "Epoch 1/5\n",
      "47678/47678 [==============================] - 29s - loss: 0.4231 - acc: 0.8341    \n",
      "Epoch 2/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.4050 - acc: 0.8365    \n",
      "Epoch 3/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3972 - acc: 0.8380    \n",
      "Epoch 4/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3912 - acc: 0.8395    \n",
      "Epoch 5/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3865 - acc: 0.8412    \n",
      "Epoch 1/5\n",
      "47678/47678 [==============================] - 29s - loss: 0.4223 - acc: 0.8337    \n",
      "Epoch 2/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.4039 - acc: 0.8368    \n",
      "Epoch 3/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3961 - acc: 0.8389    \n",
      "Epoch 4/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3901 - acc: 0.8398    \n",
      "Epoch 5/5\n",
      "47678/47678 [==============================] - 27s - loss: 0.3855 - acc: 0.8411    \n",
      "Epoch 1/5\n",
      "47679/47679 [==============================] - 30s - loss: 0.4241 - acc: 0.8334    \n",
      "Epoch 2/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.4050 - acc: 0.8368    \n",
      "Epoch 3/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.3969 - acc: 0.8386    \n",
      "Epoch 4/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3911 - acc: 0.8401    \n",
      "Epoch 5/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.3867 - acc: 0.8414    \n",
      "Epoch 1/5\n",
      "47679/47679 [==============================] - 30s - loss: 0.4238 - acc: 0.8331    \n",
      "Epoch 2/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.4032 - acc: 0.8376    \n",
      "Epoch 3/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.3949 - acc: 0.8395    \n",
      "Epoch 4/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.3887 - acc: 0.8409    \n",
      "Epoch 5/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.3840 - acc: 0.8419    \n",
      "Epoch 1/5\n",
      "47679/47679 [==============================] - 30s - loss: 0.4235 - acc: 0.8337    \n",
      "Epoch 2/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.4053 - acc: 0.8370    \n",
      "Epoch 3/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3980 - acc: 0.8384    \n",
      "Epoch 4/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3923 - acc: 0.8399    \n",
      "Epoch 5/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3880 - acc: 0.8408    \n",
      "Epoch 1/5\n",
      "47679/47679 [==============================] - 30s - loss: 0.4243 - acc: 0.8328    \n",
      "Epoch 2/5\n",
      "47679/47679 [==============================] - 27s - loss: 0.4048 - acc: 0.8370    \n",
      "Epoch 3/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3968 - acc: 0.8386    \n",
      "Epoch 4/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3913 - acc: 0.8397    \n",
      "Epoch 5/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3870 - acc: 0.8411    \n",
      "Epoch 1/5\n",
      "47679/47679 [==============================] - 31s - loss: 0.4223 - acc: 0.8341    \n",
      "Epoch 2/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.4039 - acc: 0.8379    \n",
      "Epoch 3/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3962 - acc: 0.8390    \n",
      "Epoch 4/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3908 - acc: 0.8399    \n",
      "Epoch 5/5\n",
      "47679/47679 [==============================] - 28s - loss: 0.3862 - acc: 0.8406    \n"
     ]
    }
   ],
   "source": [
    "num_folds = 10\n",
    "\n",
    "model_list1 = []\n",
    "yhat_list1 = []\n",
    "y_test_list1 = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
    "for iter_num, (train_indices, test_indices) in enumerate(skf.split(df_train.drop(['readmitted'], axis = 1), df_train['readmitted'])):\n",
    "    df_train_cv = df_train.iloc[train_indices]\n",
    "    df_test_cv = df_train.iloc[test_indices]\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_branch_outputs = []\n",
    "    \n",
    "    categorical_headers_ints = [x+'_int' for x in categorical_headers]\n",
    "    master_numeric_headers = numeric_headers + int_categorical_headers\n",
    "    df_num =  df_train_cv[master_numeric_headers].values\n",
    "    X_train_num =  df_train_cv[master_numeric_headers].values\n",
    "    X_test_num =  df_test_cv[master_numeric_headers].values\n",
    "    y_train = df_train_cv['readmitted'].values.astype(np.int)\n",
    "    y_test = df_test_cv['readmitted'].values.astype(np.int)\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        # needs to be commented better, Eric!\n",
    "        X_crossed_train = df_train_cv[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "        X_crossed_test = df_test_cv[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_branch_outputs)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train_cv[col].values )\n",
    "        X_ints_test.append( df_test_cv[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False,name='numeric_data'))\n",
    "    x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "    all_branch_outputs.append( x )\n",
    "\n",
    "    # merge the branches together\n",
    "    deep_branch = concatenate(all_branch_outputs)\n",
    "    deep_branch = Dense(units=50,activation='relu')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu')(deep_branch)\n",
    "\n",
    "    final_branch = concatenate([wide_branch, deep_branch])\n",
    "    final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "    modeltemp = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "    modeltemp.compile(optimizer='adagrad',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    modeltemp.fit(X_ints_train+ [X_train_num],\n",
    "            y_train, epochs=5, batch_size=32, verbose=1)\n",
    "    model_list1.append(modeltemp)\n",
    "    yhat_temp = np.round(modeltemp.predict(X_ints_test + [X_test_num]))\n",
    "    yhat_list1.append(yhat_temp)\n",
    "    y_test_list1.append(y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generalization Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial network was a generic wide and deep network, but we wanted to modify the network architecture in an attempt to achieve higher performance. Having two different network architectures to choose from could help us improve our generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper \"Deep\" Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our second network architecture modification, we are adding layers to the deep part of the wide and deep network. In our initial wide and deep network only had two deep layers. For this network modification, we will be adding three more layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Due to timing constraints and computational limits, for the training and testing of this next architecture, we reduced our Stratified K Folds from 10 to 5 out of necessity. Within the context of time sensitivity, we believed it would be far more appropriate to reduce the number of folds, rather than reduce the number of epochs. This is due to the fact that the number of epochs has a significant impact on the performance, whereas the number of folds only impacts our __confidence__ in our generalization performance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "39731/39731 [==============================] - 27s - loss: 0.4255 - acc: 0.8331    \n",
      "Epoch 2/5\n",
      "39731/39731 [==============================] - 25s - loss: 0.4055 - acc: 0.8368    \n",
      "Epoch 3/5\n",
      "39731/39731 [==============================] - 25s - loss: 0.3967 - acc: 0.8377    \n",
      "Epoch 4/5\n",
      "39731/39731 [==============================] - 25s - loss: 0.3897 - acc: 0.8391    \n",
      "Epoch 5/5\n",
      "39731/39731 [==============================] - 24s - loss: 0.3842 - acc: 0.8402    \n",
      "Epoch 1/5\n",
      "39732/39732 [==============================] - 27s - loss: 0.4250 - acc: 0.8335    \n",
      "Epoch 2/5\n",
      "39732/39732 [==============================] - 25s - loss: 0.4024 - acc: 0.8379    \n",
      "Epoch 3/5\n",
      "39732/39732 [==============================] - 25s - loss: 0.3918 - acc: 0.8401    \n",
      "Epoch 4/5\n",
      "39732/39732 [==============================] - 25s - loss: 0.3841 - acc: 0.8425    \n",
      "Epoch 5/5\n",
      "39732/39732 [==============================] - 25s - loss: 0.3768 - acc: 0.8446    \n",
      "Epoch 1/5\n",
      "39732/39732 [==============================] - 28s - loss: 0.4243 - acc: 0.8344    \n",
      "Epoch 2/5\n",
      "39732/39732 [==============================] - 25s - loss: 0.4049 - acc: 0.8372    \n",
      "Epoch 3/5\n",
      "39732/39732 [==============================] - 25s - loss: 0.3960 - acc: 0.8385    \n",
      "Epoch 4/5\n",
      "39732/39732 [==============================] - 24s - loss: 0.3894 - acc: 0.8392    \n",
      "Epoch 5/5\n",
      "39732/39732 [==============================] - 25s - loss: 0.3843 - acc: 0.8411    \n",
      "Epoch 1/5\n",
      "39733/39733 [==============================] - 28s - loss: 0.4270 - acc: 0.8327    \n",
      "Epoch 2/5\n",
      "39733/39733 [==============================] - 25s - loss: 0.4060 - acc: 0.8368    \n",
      "Epoch 3/5\n",
      "39733/39733 [==============================] - 25s - loss: 0.3970 - acc: 0.8384    \n",
      "Epoch 4/5\n",
      "39733/39733 [==============================] - 25s - loss: 0.3899 - acc: 0.8405    \n",
      "Epoch 5/5\n",
      "39733/39733 [==============================] - 25s - loss: 0.3842 - acc: 0.8421    \n"
     ]
    }
   ],
   "source": [
    "model_list2 = []\n",
    "yhat_list2 = []\n",
    "y_test_list2 = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "for iter_num, (train_indices, test_indices) in enumerate(skf.split(df_train.drop(['readmitted'], axis = 1), df_train['readmitted'])):\n",
    "    df_train_cv = df_train.iloc[train_indices]\n",
    "    df_test_cv = df_train.iloc[test_indices]\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_branch_outputs = []\n",
    "    \n",
    "    categorical_headers_ints = [x+'_int' for x in categorical_headers]\n",
    "    master_numeric_headers = numeric_headers + int_categorical_headers\n",
    "    df_num =  df_train_cv[master_numeric_headers].values\n",
    "    X_train_num =  df_train_cv[master_numeric_headers].values\n",
    "    X_test_num =  df_test_cv[master_numeric_headers].values\n",
    "    y_train = df_train_cv['readmitted'].values.astype(np.int)\n",
    "    y_test = df_test_cv['readmitted'].values.astype(np.int)\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        # needs to be commented better, Eric!\n",
    "        X_crossed_train = df_train_cv[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "        X_crossed_test = df_test_cv[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_branch_outputs)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train_cv[col].values )\n",
    "        X_ints_test.append( df_test_cv[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False,name='numeric_data'))\n",
    "    x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "    all_branch_outputs.append( x )\n",
    "\n",
    "    # merge the branches together\n",
    "    deep_branch = concatenate(all_branch_outputs)\n",
    "    deep_branch = Dense(units=50,activation='relu')(deep_branch)\n",
    "    deep_branch = Dense(units=40,activation='relu')(deep_branch)\n",
    "    deep_branch = Dense(units=30,activation='relu')(deep_branch)\n",
    "    deep_branch = Dense(units=20,activation='relu')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu')(deep_branch)\n",
    "\n",
    "    final_branch = concatenate([wide_branch, deep_branch])\n",
    "    final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "    modeltemp = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "    modeltemp.compile(optimizer='adagrad',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    modeltemp.fit(X_ints_train+ [X_train_num],\n",
    "            y_train, epochs=5, batch_size=32, verbose=1)\n",
    "    model_list2.append(modeltemp)\n",
    "    yhat_temp = np.round(modeltemp.predict(X_ints_test + [X_test_num]))\n",
    "    yhat_list2.append(yhat_temp)\n",
    "    y_test_list2.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model3).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Performance of Two Different Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first visualization is of the performance of the original wide and deep network. Though the verbose output for the above training displays accuracy, we must remind ourselves that we will be using recall score as our primary measure of performance. Again, we wish to penalize instances in which a classifier would yield a false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4301   89]\n",
      " [ 784  125]] 0.137513751375\n",
      "[[4294   95]\n",
      " [ 775  134]] 0.147414741474\n",
      "[[4306   83]\n",
      " [ 790  119]] 0.130913091309\n",
      "[[4280  109]\n",
      " [ 770  139]] 0.152915291529\n",
      "[[4280  109]\n",
      " [ 790  119]] 0.130913091309\n",
      "[[4319   70]\n",
      " [ 806  102]] 0.112334801762\n",
      "[[4261  128]\n",
      " [ 800  108]] 0.118942731278\n",
      "[[4287  102]\n",
      " [ 785  123]] 0.135462555066\n",
      "[[4312   77]\n",
      " [ 797  111]] 0.122246696035\n",
      "[[4293   96]\n",
      " [ 798  110]] 0.121145374449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x254328a59b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores1 = []\n",
    "\n",
    "for i in range(0, len(yhat_list1)):\n",
    "    print(mt.confusion_matrix(y_test_list1[i],yhat_list1[i]), mt.recall_score(y_test_list1[i],yhat_list1[i]))\n",
    "    scores1.append(mt.recall_score(y_test_list1[i],yhat_list1[i]))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "i = list(range(1,num_folds+1))\n",
    "plt.bar(i,scores1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by our recall score, our recall score is horrendous. Especially within the scope of our business case, we would not want to deploy this classifier to a real world application for hospitals, in which lives are at stake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10754   219]\n",
      " [ 1962   310]] 0.136443661972\n",
      "[[10703   270]\n",
      " [ 2001   270]] 0.118890356671\n",
      "[[10684   289]\n",
      " [ 1945   326]] 0.143549097314\n",
      "[[10658   314]\n",
      " [ 1913   358]] 0.157639806253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 4 artists>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAE+5JREFUeJzt3X+QXfd51/H3J5LllITawV4gWHKl\njNUZ1jQEZ62mU2IyCaRyQy1mKoMcIHbHjICgASaEojCgNGo7U1NadyBmGhWbOjZGNqbpiHiDamIo\nM53U1dpOnMiuykYYa6PMWIkdBxMcV/bDH/cIrm+uvGd/SHfT7/s1s+Nzvuc55z77tfZz756759xU\nFZKkNrxu0g1Iks4fQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkPWTbmDUpZde\nWps3b550G5L0XeWRRx75WlVNLVa35kJ/8+bNzM3NTboNSfqukuR/9qnz9I4kNcTQl6SG9Ar9JNuT\nHEsyn2TvmO3XJHk0yekkO0e2XZ7kN5I8meSJJJtXp3VJ0lItGvpJ1gG3AdcC08ANSaZHyp4GbgLu\nGXOITwI/X1V/EtgGPLOShiVJy9fnjdxtwHxVHQdIchDYATxxpqCqnuq2vTK8Y/fksL6qHuzqXlid\ntiVJy9Hn9M5lwImh9YVurI/vB76R5NeSPJbk57vfHCRJE9An9DNmrO/Hba0H3gl8GLgaeAuD00Cv\nfoBkd5K5JHOnTp3qeWhJ0lL1Cf0FYNPQ+kbgZM/jLwCPVdXxqjoN/Dpw1WhRVR2oqpmqmpmaWvTa\nAknSMvUJ/SPA1iRbkmwAdgGHeh7/CPCmJGeS/N0MvRcgSTq/Fn0jt6pOJ9kDHAbWAXdU1dEk+4G5\nqjqU5GrgU8CbgB9L8rGqurKqXk7yYeCzSQI8AvzKuft2JH0327z3gUm3MFFP/dz7zvlj9LoNQ1XN\nArMjY/uGlo8wOO0zbt8HgbeuoEdJ0irxilxJaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi\n6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkN6fYiKpH785Kdz/8lPWple\nr/STbE9yLMl8kr1jtl+T5NEkp5PsHLP9e5N8JcnHV6NpSdLyLBr6SdYBtwHXAtPADUmmR8qeBm4C\n7jnLYX4a+M3ltylJWg19XulvA+ar6nhVvQQcBHYMF1TVU1X1OPDK6M5J3g78MeA3VqFfSdIK9An9\ny4ATQ+sL3diikrwO+AXgHy69NUnSausT+hkzVj2P/0FgtqpOvFZRkt1J5pLMnTp1quehJUlL1eev\ndxaATUPrG4GTPY//Q8A7k3wQeCOwIckLVfWqN4Or6gBwAGBmZqbvE4okaYn6hP4RYGuSLcBXgF3A\n+/scvKr+6pnlJDcBM6OBL0k6fxY9vVNVp4E9wGHgSeC+qjqaZH+S6wCSXJ1kAbge+ESSo+eyaUnS\n8vS6OKuqZoHZkbF9Q8tHGJz2ea1j/Crwq0vuUJK0av7AXZHrFZFeESnp7Lz3jiQ1xNCXpIYY+pLU\nEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x\n9CWpIYa+JDWkV+gn2Z7kWJL5JN/xweZJrknyaJLTSXYOjb8tyeeSHE3yeJK/sprNS5KWZtHQT7IO\nuA24FpgGbkgyPVL2NHATcM/I+LeAD1TVlcB24JeSXLzSpiVJy9PnM3K3AfNVdRwgyUFgB/DEmYKq\neqrb9srwjlX1e0PLJ5M8A0wB31hx55KkJetzeucy4MTQ+kI3tiRJtgEbgC+P2bY7yVySuVOnTi31\n0JKknvqEfsaM1VIeJMmbgbuAn6iqV0a3V9WBqpqpqpmpqamlHFqStAR9Tu8sAJuG1jcCJ/s+QJLv\nBR4A/klV/fbS2tP5tnnvA5NuYaKe+rn3TboF6Zzq80r/CLA1yZYkG4BdwKE+B+/qPwV8sqr+/fLb\nlCSthkVDv6pOA3uAw8CTwH1VdTTJ/iTXASS5OskCcD3wiSRHu93/MnANcFOSz3dfbzsn34kkaVF9\nTu9QVbPA7MjYvqHlIwxO+4zudzdw9wp7lCStEq/IlaSGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x\n9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIb0Cv0k25Mc\nSzKfZO+Y7dckeTTJ6SQ7R7bdmOS/d183rlbjkqSlWzT0k6wDbgOuBaaBG5JMj5Q9DdwE3DOy7x8B\nPgr8ILAN+GiSN628bUnScvR5pb8NmK+q41X1EnAQ2DFcUFVPVdXjwCsj+/4I8GBVPVtVzwEPAttX\noW9J0jL0Cf3LgBND6wvdWB+99k2yO8lckrlTp071PLQkaan6hH7GjFXP4/fat6oOVNVMVc1MTU31\nPLQkaan6hP4CsGlofSNwsufxV7KvJGmV9Qn9I8DWJFuSbAB2AYd6Hv8w8N4kb+rewH1vNyZJmoBF\nQ7+qTgN7GIT1k8B9VXU0yf4k1wEkuTrJAnA98IkkR7t9nwV+msETxxFgfzcmSZqA9X2KqmoWmB0Z\n2ze0fITBqZtx+94B3LGCHiVJq8QrciWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN\nMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhvUI/yfYkx5LMJ9k7ZvuF\nSe7ttj+cZHM3fkGSO5N8McmTST6yuu1LkpZi0dBPsg64DbgWmAZuSDI9UnYz8FxVXQHcCtzSjV8P\nXFhVPwC8HfibZ54QJEnnX59X+tuA+ao6XlUvAQeBHSM1O4A7u+X7gfckCVDAG5KsB74HeAn45qp0\nLklasj6hfxlwYmh9oRsbW1NVp4HngUsYPAH8b+CrwNPAP6+qZ1fYsyRpmfqEfsaMVc+abcDLwJ8A\ntgD/IMlbvuMBkt1J5pLMnTp1qkdLkqTl6BP6C8CmofWNwMmz1XSnci4CngXeD/ynqvr9qnoG+C1g\nZvQBqupAVc1U1czU1NTSvwtJUi99Qv8IsDXJliQbgF3AoZGaQ8CN3fJO4KGqKgandN6dgTcA7wB+\nd3ValyQt1aKh352j3wMcBp4E7quqo0n2J7muK7sduCTJPPAh4Myfdd4GvBH4EoMnj39TVY+v8vcg\nSeppfZ+iqpoFZkfG9g0tv8jgzzNH93th3LgkaTK8IleSGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1\nxNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5Ia0iv0k2xP\ncizJfJK9Y7ZfmOTebvvDSTYPbXtrks8lOZrki0lev3rtS5KWYtHQT7KOwWfdXgtMAzckmR4puxl4\nrqquAG4Fbun2XQ/cDfytqroSeBfw+6vWvSRpSfq80t8GzFfV8ap6CTgI7Bip2QHc2S3fD7wnSYD3\nAo9X1RcAqurrVfXy6rQuSVqqPqF/GXBiaH2hGxtbU1WngeeBS4DvByrJ4SSPJvnJlbcsSVqu9T1q\nMmasetasB/4scDXwLeCzSR6pqs++audkN7Ab4PLLL+/RkiRpOfq80l8ANg2tbwROnq2mO49/EfBs\nN/6bVfW1qvoWMAtcNfoAVXWgqmaqamZqamrp34UkqZc+oX8E2JpkS5INwC7g0EjNIeDGbnkn8FBV\nFXAYeGuSP9Q9Gfw54InVaV2StFSLnt6pqtNJ9jAI8HXAHVV1NMl+YK6qDgG3A3clmWfwCn9Xt+9z\nSX6RwRNHAbNV9cA5+l4kSYvoc06fqpplcGpmeGzf0PKLwPVn2fduBn+2KUmaMK/IlaSGGPqS1BBD\nX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQl\nqSGGviQ1xNCXpIYY+pLUkF6hn2R7kmNJ5pPsHbP9wiT3dtsfTrJ5ZPvlSV5I8uHVaVuStByLhn6S\ndcBtwLXANHBDkumRspuB56rqCuBW4JaR7bcCn1l5u5KklejzSn8bMF9Vx6vqJeAgsGOkZgdwZ7d8\nP/CeJAFI8peA48DR1WlZkrRcfUL/MuDE0PpCNza2pqpOA88DlyR5A/CPgI+91gMk2Z1kLsncqVOn\n+vYuSVqiPqGfMWPVs+ZjwK1V9cJrPUBVHaiqmaqamZqa6tGSJGk51veoWQA2Da1vBE6epWYhyXrg\nIuBZ4AeBnUn+GXAx8EqSF6vq4yvuXJK0ZH1C/wiwNckW4CvALuD9IzWHgBuBzwE7gYeqqoB3nilI\n8lPACwa+JE3OoqFfVaeT7AEOA+uAO6rqaJL9wFxVHQJuB+5KMs/gFf6uc9m0JGl5+rzSp6pmgdmR\nsX1Dyy8C1y9yjJ9aRn+SpFXkFbmS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6\nktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkF6hn2R7kmNJ5pPsHbP9wiT3\ndtsfTrK5G/8LSR5J8sXuv+9e3fYlSUuxaOgnWQfcBlwLTAM3JJkeKbsZeK6qrgBuBW7pxr8G/FhV\n/QCDD06/a7UalyQtXZ9X+tuA+ao6XlUvAQeBHSM1O4A7u+X7gfckSVU9VlUnu/GjwOuTXLgajUuS\nlq5P6F8GnBhaX+jGxtZU1WngeeCSkZofBx6rqm8vr1VJ0kqt71GTMWO1lJokVzI45fPesQ+Q7AZ2\nA1x++eU9WpIkLUefV/oLwKah9Y3AybPVJFkPXAQ8261vBD4FfKCqvjzuAarqQFXNVNXM1NTU0r4D\nSVJvfUL/CLA1yZYkG4BdwKGRmkMM3qgF2Ak8VFWV5GLgAeAjVfVbq9W0JGl5Fg397hz9HuAw8CRw\nX1UdTbI/yXVd2e3AJUnmgQ8BZ/6scw9wBfBPk3y++/qjq/5dSJJ66XNOn6qaBWZHxvYNLb8IXD9m\nv58BfmaFPUqSVolX5EpSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlq\niKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDeoV+ku1JjiWZT7J3zPYLk9zbbX84yeah\nbR/pxo8l+ZHVa12StFSLhn6SdcBtwLXANHBDkumRspuB56rqCuBW4JZu32kGH6R+JbAd+Ffd8SRJ\nE9Dnlf42YL6qjlfVS8BBYMdIzQ7gzm75fuA9SdKNH6yqb1fV/wDmu+NJkiagT+hfBpwYWl/oxsbW\nVNVp4Hngkp77SpLOk/U9ajJmrHrW9NmXJLuB3d3qC0mOvUY/lwJfe43tkzbR/nLLoiXO32tw/lbG\n+VuZFc7f9/V5jD6hvwBsGlrfCJw8S81CkvXARcCzPfelqg4AB/o0nGSuqmb61E6C/a2M/a2M/a1M\nC/31Ob1zBNiaZEuSDQzemD00UnMIuLFb3gk8VFXVje/q/rpnC7AV+J2VNCxJWr5FX+lX1ekke4DD\nwDrgjqo6mmQ/MFdVh4DbgbuSzDN4hb+r2/dokvuAJ4DTwN+pqpfP0fciSVpEn9M7VNUsMDsytm9o\n+UXg+rPs+7PAz66gx1G9TgNNkP2tjP2tjP2tzB/4/jI4CyNJaoG3YZCkhqzJ0O9x24ebkpxK8vnu\n62+c5/7uSPJMki+dZXuS/Iuu/8eTXLXG+ntXkueH5m/fuLpz2N+mJP8lyZNJjib5e2NqJjaHPfub\n2BwmeX2S30nyha6/j42pOeutUdZIfxP9Ge56WJfksSSfHrNtYvPXs7/lz19VrakvBm8Wfxl4C7AB\n+AIwPVJzE/DxCfZ4DXAV8KWzbP9R4DMMrlN4B/DwGuvvXcCnJzh/bwau6pb/MPB7Y/4fT2wOe/Y3\nsTns5uSN3fIFwMPAO0ZqPgj8cre8C7h3jfU30Z/hrocPAfeM+/84yfnr2d+y528tvtLvc9uHiaqq\n/8bgr5TOZgfwyRr4beDiJG8+P9316m+iquqrVfVot/y/gCf5ziu1JzaHPfubmG5OXuhWL+i+Rt+c\nO9utUdZKfxOVZCPwPuBfn6VkYvMHvfpbtrUY+n1v3fDj3a/99yfZNGb7JH033H7ih7pfvz+T5MpJ\nNdH92vxnGLwaHLYm5vA1+oMJzmH3q//ngWeAB6vqrPNXr741ylrpDyb7M/xLwE8Cr5xl+0Tnj8X7\ng2XO31oM/T63bviPwOaqeivwn/n/z8hrRa/bT0zQo8D3VdWfBv4l8OuTaCLJG4H/APz9qvrm6OYx\nu5zXOVykv4nOYVW9XFVvY3CV+7Ykf2qkZKLz16O/if0MJ/mLwDNV9chrlY0ZOy/z17O/Zc/fWgz9\nRW/dUFVfr6pvd6u/Arz9PPXWV6/bT0xKVX3zzK/fNbgG44Ikl57PHpJcwCBQ/21V/dqYkonO4WL9\nrYU57B77G8B/ZXDr8mH/b/7y6lujnFdn62/CP8M/DFyX5CkGp4/fneTukZpJzt+i/a1k/tZi6C96\n24eRc7vXMTjnupYcAj7Q/QXKO4Dnq+qrk27qjCR//Mz5ySTbGPw7+Pp5fPwwuIr7yar6xbOUTWwO\n+/Q3yTlMMpXk4m75e4A/D/zuSNnZbo2yJvqb5M9wVX2kqjZW1WYG+fJQVf21kbKJzV+f/lYyf72u\nyD2fqt9tH/5ukusY3NrhWQbvZJ83Sf4dg7/euDTJAvBRBm9WUVW/zODq5R9l8PkB3wJ+Yo31txP4\n20lOA/8H2HW+/kF3fhj468AXu/O+AP8YuHyox0nOYZ/+JjmHbwbuzOADiV4H3FdVn06PW6Osof4m\n+jM8zhqav7FWa/68IleSGrIWT+9Iks4RQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIb8\nX/qbVBURGt5iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x254349b0048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores2 = []\n",
    "\n",
    "for i in range(0, len(yhat_list2)):\n",
    "    print(mt.confusion_matrix(y_test_list2[i],yhat_list2[i]), mt.recall_score(y_test_list2[i],yhat_list2[i]))\n",
    "    scores2.append(mt.recall_score(y_test_list2[i],yhat_list2[i]))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "i = list(range(1,5))\n",
    "plt.bar(i,scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can observe from the two results above, it is extremely apparent why we cannot just rely on accuracy score when analyzing our classification performance. If this lab has taught us anything, it has strongly reinforced our knowledge when it comes to choosing a proper evaluation metric.\n",
    "\n",
    "Though our accuracy score was consistently above 80%, our recall score indicates that our classification model is not usable for our business case, in a real world deployed scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Performance Analysis Compared to Scikit-Learn MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have determined the better network architecture, how would our wide and deep network fare against the Scikit-Learn MultiLayer Perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect Tensorflow to perform better because it is optimized to perform better with GPU's. It does not prioritize training speed, and instead prioritizes performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Again, due to timing constraints, we must limit the number of cross validation folds. With more time, we would be able to provide a higher confidence in our generalization performance when compared to Scikit-Learn.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7765  136]\n",
      " [1476  159]] 0.540017347705\n",
      "[[7705  196]\n",
      " [1440  195]] 0.547229534294\n",
      "[[7609  292]\n",
      " [1385  250]] 0.557973925803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ovall\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7580  321]\n",
      " [1348  287]] 0.567453699779\n",
      "[[7721  180]\n",
      " [1429  206]] 0.551605978727\n",
      "[[7870   31]\n",
      " [1574   61]] 0.516692657261\n",
      "[[7802   99]\n",
      " [1502  133]] 0.534407753132\n",
      "[[7732  169]\n",
      " [1407  228]] 0.559029921889\n",
      "[[7493  408]\n",
      " [1311  324]] 0.57326305229\n",
      "[[7693  208]\n",
      " [1394  241]] 0.560537415037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "yhat_list_sk = []\n",
    "y_test_list_sk = []\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=, shuffle=True)\n",
    "for iter_num, (train_indices, test_indices) in enumerate(skf.split(df_train.drop(['readmitted'], axis = 1), df_train['readmitted'])):\n",
    "    df_train_cv = df_train.iloc[train_indices]\n",
    "    df_test_cv = df_train.iloc[test_indices]\n",
    "    \n",
    "    df_dummies = pd.get_dummies(df_train_cv, columns=categorical_headers)\n",
    "\n",
    "    df_dummies_train, df_dummies_test = train_test_split(df_dummies, test_size=0.2, stratify=df_dummies['readmitted'])\n",
    "    y_train_sk = df_dummies_train['readmitted']\n",
    "    y_test_sk = df_dummies_test['readmitted']\n",
    "    df_dummies_train.drop(['readmitted'], axis=1, inplace=True)\n",
    "    df_dummies_test.drop(['readmitted'], axis=1, inplace=True)\n",
    "\n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X=df_dummies_train.values, y=np.asarray(y_train_sk.values, dtype=\"|S6\"))\n",
    "    yhat_sk = clf.predict(df_dummies_test.values)\n",
    "    yhat_list_sk.append(yhat_sk.astype(int))\n",
    "    y_test_list_sk.append(y_test_sk.values.astype(int))\n",
    "    print(mt.confusion_matrix(y_test_sk.values.astype(int),yhat_sk.astype(int)),mt.roc_auc_score(y_test_sk.values.astype(int),yhat_sk.astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With receiver operating characteristic and area under the curve scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7765  136]\n",
      " [1476  159]] 0.540017347705\n",
      "[[7705  196]\n",
      " [1440  195]] 0.547229534294\n",
      "[[7609  292]\n",
      " [1385  250]] 0.557973925803\n",
      "[[7580  321]\n",
      " [1348  287]] 0.567453699779\n",
      "[[7721  180]\n",
      " [1429  206]] 0.551605978727\n",
      "[[7870   31]\n",
      " [1574   61]] 0.516692657261\n",
      "[[7802   99]\n",
      " [1502  133]] 0.534407753132\n",
      "[[7732  169]\n",
      " [1407  228]] 0.559029921889\n",
      "[[7493  408]\n",
      " [1311  324]] 0.57326305229\n",
      "[[7693  208]\n",
      " [1394  241]] 0.560537415037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQ1BoIkCYD/D4qmd/i2lZ2OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x254345e6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_sk = []\n",
    "\n",
    "for i in range(0, len(yhat_list_sk)):\n",
    "    print(mt.confusion_matrix(y_test_list_sk[i],yhat_list_sk[i]), mt.roc_auc_score(y_test_list_sk[i],yhat_list_sk[i]))\n",
    "    scores_sk.append(mt.recall_score(y_test_list_sk[i],yhat_list_sk[i]))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "i = list(range(1,11))\n",
    "plt.bar(i,scores_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With recall scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7765  136]\n",
      " [1476  159]] 0.097247706422\n",
      "[[7705  196]\n",
      " [1440  195]] 0.119266055046\n",
      "[[7609  292]\n",
      " [1385  250]] 0.152905198777\n",
      "[[7580  321]\n",
      " [1348  287]] 0.175535168196\n",
      "[[7721  180]\n",
      " [1429  206]] 0.125993883792\n",
      "[[7870   31]\n",
      " [1574   61]] 0.0373088685015\n",
      "[[7802   99]\n",
      " [1502  133]] 0.0813455657492\n",
      "[[7732  169]\n",
      " [1407  228]] 0.139449541284\n",
      "[[7493  408]\n",
      " [1311  324]] 0.198165137615\n",
      "[[7693  208]\n",
      " [1394  241]] 0.147400611621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQ1BoIkCYD/D4qmd/i2lZ2OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25434adf550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_sk = []\n",
    "\n",
    "for i in range(0, len(yhat_list_sk)):\n",
    "    print(mt.confusion_matrix(y_test_list_sk[i],yhat_list_sk[i]), mt.recall_score(y_test_list_sk[i],yhat_list_sk[i]))\n",
    "    scores_sk.append(mt.recall_score(y_test_list_sk[i],yhat_list_sk[i]))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "i = list(range(1,11))\n",
    "plt.bar(i,scores_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the performance of Scikit-Learn's MLP classifier, we can conclude that the Tensorflow implementation is superior in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Architecture Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to experiment with the performance changes with adding deep layers at the final stage, rather than adding deep layers to the \"deep portion\" of the network like we did above. Due to time constraints, we were unable to train the model in time to conduct analysis. However, we did want to leave the implementation here in case.\n",
    "\n",
    "In our own personal testing, we found that adding more layers to the deeper portion to the network had higher performance than adding more layers to the final layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create separate sequential models for each embedding\n",
    "import tensorflow as tf\n",
    "with tf.device('/GPU:0'):\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        # needs to be commented better, Eric!\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_branch_outputs)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False,name='numeric_data'))\n",
    "    x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "    all_branch_outputs.append( x )\n",
    "\n",
    "    # merge the branches together\n",
    "    deep_branch = concatenate(all_branch_outputs)\n",
    "    deep_branch = Dense(units=50,activation='relu')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu')(deep_branch)\n",
    "\n",
    "    final_branch = concatenate([wide_branch, deep_branch])\n",
    "    final_branch = Dense(units=50,activation='sigmoid')(final_branch)\n",
    "    final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "    model3 = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "    model3.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model3.fit(X_ints_train+ [X_train_num],\n",
    "            y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
