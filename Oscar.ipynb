{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/diabetic_data.csv', encoding = 'latin1',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital    ...     citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1    ...              No      No                   No   \n",
       "1                 3    ...              No      Up                   No   \n",
       "2                 2    ...              No      No                   No   \n",
       "3                 2    ...              No      Up                   No   \n",
       "4                 1    ...              No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/diabetic_data.csv', encoding = 'latin1',low_memory=False)\n",
    "df.readmitted[df.readmitted == 'NO' ] = 0\n",
    "df.readmitted[df.readmitted == '<30' ] = 1\n",
    "df = df.drop(df[df.readmitted == '>30'].index)\n",
    "df.drop(['encounter_id', 'patient_nbr', 'weight', 'payer_code', 'medical_specialty'], axis=1, inplace=True)\n",
    "df.dropna(axis=1, how='all')\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['readmitted'])\n",
    "#X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin-rosiglitazone_int</th>\n",
       "      <th>metformin-pioglitazone_int</th>\n",
       "      <th>change_int</th>\n",
       "      <th>diabetesMed_int</th>\n",
       "      <th>admission_type_id_int</th>\n",
       "      <th>discharge_disposition_id_int</th>\n",
       "      <th>admission_source_id_int</th>\n",
       "      <th>diag_1_int</th>\n",
       "      <th>diag_2_int</th>\n",
       "      <th>diag_3_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80816</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.114867</td>\n",
       "      <td>0.573128</td>\n",
       "      <td>-0.225250</td>\n",
       "      <td>-0.343702</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>518</td>\n",
       "      <td>518</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52582</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.226448</td>\n",
       "      <td>0.725258</td>\n",
       "      <td>0.355127</td>\n",
       "      <td>-0.343702</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>722</td>\n",
       "      <td>324</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93135</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.450195</td>\n",
       "      <td>-1.252430</td>\n",
       "      <td>-0.805627</td>\n",
       "      <td>-0.701502</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>V09</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31765</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[60-70)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.120853</td>\n",
       "      <td>0.370288</td>\n",
       "      <td>-0.805627</td>\n",
       "      <td>-1.178569</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>427</td>\n",
       "      <td>250.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69163</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.785524</td>\n",
       "      <td>-1.708820</td>\n",
       "      <td>-0.225250</td>\n",
       "      <td>0.371899</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>245</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            race  gender      age  admission_type_id  \\\n",
       "80816  Caucasian  Female  [70-80)                  1   \n",
       "52582  Caucasian    Male  [60-70)                  1   \n",
       "93135      Asian  Female  [70-80)                  1   \n",
       "31765  Caucasian  Female  [60-70)                  1   \n",
       "69163  Caucasian  Female  [40-50)                  3   \n",
       "\n",
       "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "80816                         1                    7         -0.114867   \n",
       "52582                         3                    7          1.226448   \n",
       "93135                         3                    7         -0.450195   \n",
       "31765                         1                    6         -1.120853   \n",
       "69163                         1                    1         -0.785524   \n",
       "\n",
       "       num_lab_procedures  num_procedures  num_medications    ...      \\\n",
       "80816            0.573128       -0.225250        -0.343702    ...       \n",
       "52582            0.725258        0.355127        -0.343702    ...       \n",
       "93135           -1.252430       -0.805627        -0.701502    ...       \n",
       "31765            0.370288       -0.805627        -1.178569    ...       \n",
       "69163           -1.708820       -0.225250         0.371899    ...       \n",
       "\n",
       "       metformin-rosiglitazone_int  metformin-pioglitazone_int  change_int  \\\n",
       "80816                            0                           0           0   \n",
       "52582                            0                           0           1   \n",
       "93135                            0                           0           0   \n",
       "31765                            0                           0           1   \n",
       "69163                            0                           0           1   \n",
       "\n",
       "      diabetesMed_int admission_type_id_int discharge_disposition_id_int  \\\n",
       "80816               1                     1                            1   \n",
       "52582               0                     1                            3   \n",
       "93135               1                     1                            3   \n",
       "31765               0                     1                            1   \n",
       "69163               1                     3                            1   \n",
       "\n",
       "       admission_source_id_int diag_1_int diag_2_int diag_3_int  \n",
       "80816                        7        518        518        401  \n",
       "52582                        7        722        324        571  \n",
       "93135                        7          8        V09        250  \n",
       "31765                        6        786        427      250.6  \n",
       "69163                        1        241        245        250  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "numeric_headers = [\"time_in_hospital\", \"num_lab_procedures\", \"num_procedures\", \"num_medications\", \"number_outpatient\", \"number_emergency\", \"number_inpatient\", \"number_diagnoses\"]\n",
    "categorical_headers = ['race',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'max_glu_serum',\n",
    " 'A1Cresult',\n",
    " 'metformin',\n",
    " 'repaglinide',\n",
    " 'nateglinide',\n",
    " 'chlorpropamide',\n",
    " 'glimepiride',\n",
    " 'acetohexamide',\n",
    " 'glipizide',\n",
    " 'glyburide',\n",
    " 'tolbutamide',\n",
    " 'pioglitazone',\n",
    " 'rosiglitazone',\n",
    " 'acarbose',\n",
    " 'miglitol',\n",
    " 'troglitazone',\n",
    " 'tolazamide',\n",
    " 'examide',\n",
    " 'citoglipton',\n",
    " 'insulin',\n",
    " 'glyburide-metformin',\n",
    " 'glipizide-metformin',\n",
    " 'glimepiride-pioglitazone',\n",
    " 'metformin-rosiglitazone',\n",
    " 'metformin-pioglitazone',\n",
    " 'change',\n",
    " 'diabetesMed']\n",
    "\n",
    "df_train.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "df_train.reset_index()\n",
    "\n",
    "df_test.replace(to_replace=' ?',value=np.nan, inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "df_test.reset_index()\n",
    "\n",
    "encoders = dict()\n",
    "\n",
    "int_categorical_headers = [\n",
    "'admission_type_id',\n",
    "'discharge_disposition_id',\n",
    "'admission_source_id',\n",
    "'diag_1',\n",
    "'diag_2',\n",
    "'diag_3',\n",
    "]\n",
    "\n",
    "for col in categorical_headers:\n",
    "    df[col] = df[col].str.strip()\n",
    "    df_train[col] = df_train[col].str.strip()\n",
    "    df_test[col] = df_test[col].str.strip()\n",
    "    \n",
    "\n",
    "    encoders[col] = LabelEncoder()\n",
    "    df[col+'_int'] = encoders[col].fit_transform(df[col])\n",
    "    df_train[col+'_int'] = encoders[col].transform(df_train[col])\n",
    "    df_test[col+'_int'] = encoders[col].transform(df_test[col])\n",
    "    \n",
    "    \n",
    "    \n",
    "for col in int_categorical_headers:\n",
    "    df[col+'_int'] = df[col]\n",
    "    df_train[col+'_int'] = df_train[col]\n",
    "    df_test[col+'_int'] = df_test[col]\n",
    "\n",
    "for col in numeric_headers:\n",
    "    df_train[col] = df_train[col].astype(np.float)\n",
    "    df_test[col] = df_test[col].astype(np.float)\n",
    "    df[col] = df[col].astype(np.float)\n",
    "    ss = StandardScaler()\n",
    "    df[col] = ss.fit_transform(df[col].values.reshape(-1, 1))\n",
    "    df_train[col] = ss.transform(df_train[col].values.reshape(-1, 1))\n",
    "    df_test[col] = ss.transform(df_test[col].values.reshape(-1, 1))\n",
    "\n",
    "    \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4653269956721579264\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6789848269\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 1072030305897702914\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting work on the actual deep and wide network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_headers_ints = [x+'_int' for x in categorical_headers]\n",
    "df_num =  df[numeric_headers].values\n",
    "X_train_num =  df_train[numeric_headers].values\n",
    "X_test_num =  df_test[numeric_headers].values\n",
    "y_train = df_train['readmitted'].values.astype(np.int)\n",
    "y_test = df_test['readmitted'].values.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52976/52976 [==============================] - 22s - loss: 0.1468 - acc: 0.8285    \n",
      "Epoch 2/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1371 - acc: 0.8285    \n",
      "Epoch 3/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1353 - acc: 0.8285    \n",
      "Epoch 4/10\n",
      "52976/52976 [==============================] - -611s - loss: 0.1339 - acc: 0.8285   \n",
      "Epoch 5/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1330 - acc: 0.8290    \n",
      "Epoch 6/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1322 - acc: 0.8305    \n",
      "Epoch 7/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1317 - acc: 0.8321    \n",
      "Epoch 8/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1314 - acc: 0.8336    \n",
      "Epoch 9/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1312 - acc: 0.8341    \n",
      "Epoch 10/10\n",
      "52976/52976 [==============================] - 21s - loss: 0.1310 - acc: 0.8343    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9043671d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to create separate sequential models for each embedding\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "X_train_num =  df_train[numeric_headers].values\n",
    "X_test_num =  df_test[numeric_headers].values\n",
    "\n",
    "for col in categorical_headers_ints:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( df_train[col].values )\n",
    "    X_ints_test.append( df_test[col].values )\n",
    "\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32')\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# also get a dense branch of the numeric features\n",
    "all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False))\n",
    "x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "all_branch_outputs.append( Dense(units=10,activation='relu')(x) )\n",
    "\n",
    "# merge the branches together\n",
    "final_branch = concatenate(all_branch_outputs)\n",
    "final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_ints_train + [X_train_num],\n",
    "        y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10887    86]\n",
      " [ 2092   180]] 0.835560588901\n"
     ]
    }
   ],
   "source": [
    "X_test_num =  df_test[numeric_headers].values\n",
    "yhat = np.round(model.predict(X_ints_test + [X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_columns = [['gender','race'],\n",
    "                 ['age', 'diag_1'],\n",
    "                ['gender', 'diag_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 9 3 ..., 3 9 3]\n",
      "[1734 1955 1326 ..., 2230 2417 1091]\n",
      "[ 819 1067  305 ...,  224 1033   17]\n"
     ]
    }
   ],
   "source": [
    "cross_columns = [['gender','race'],\n",
    "                 ['age', 'diag_1'],\n",
    "                ['gender', 'diag_1']]\n",
    "\n",
    "# we need to create separate sequential models for each embedding\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # create crossed labels\n",
    "    X_crossed_train = df_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = df_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    print(X_crossed_train)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32')\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52976/52976 [==============================] - 7s - loss: 0.1699 - acc: 0.8255     \n",
      "Epoch 2/10\n",
      "52976/52976 [==============================] - 6s - loss: 0.1439 - acc: 0.8285     \n",
      "Epoch 3/10\n",
      "52976/52976 [==============================] - 6s - loss: 0.1423 - acc: 0.8285     \n",
      "Epoch 4/10\n",
      "52976/52976 [==============================] - 6s - loss: 0.1420 - acc: 0.8285     \n",
      "Epoch 5/10\n",
      "52976/52976 [==============================] - 6s - loss: 0.1419 - acc: 0.8285     \n",
      "Epoch 6/10\n",
      "52976/52976 [==============================] - 6s - loss: 0.1419 - acc: 0.8285     \n",
      "Epoch 7/10\n",
      "52976/52976 [==============================] - 6s - loss: 0.1418 - acc: 0.8285     \n",
      "Epoch 8/10\n",
      "52976/52976 [==============================] - ETA: 0s - loss: 0.1416 - acc: 0.828 - 6s - loss: 0.1418 - acc: 0.8285     \n",
      "Epoch 9/10\n",
      "52976/52976 [==============================] - 7s - loss: 0.1418 - acc: 0.8285     \n",
      "Epoch 10/10\n",
      "52976/52976 [==============================] - 6s - loss: 0.1417 - acc: 0.8285     \n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "# merge the branches together\n",
    "final_branch = concatenate(all_branch_outputs)\n",
    "final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_ints_train,\n",
    "            y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10973     0]\n",
      " [ 2272     0]] 0.828463571159\n"
     ]
    }
   ],
   "source": [
    "yhat = np.round(model.predict(X_ints_test))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52976/52976 [==============================] - 30s - loss: 0.4229 - acc: 0.8343    \n",
      "Epoch 2/10\n",
      "52976/52976 [==============================] - 28s - loss: 0.4104 - acc: 0.8370    \n",
      "Epoch 3/10\n",
      "52976/52976 [==============================] - 28s - loss: 0.4048 - acc: 0.8377    \n",
      "Epoch 4/10\n",
      "52976/52976 [==============================] - 28s - loss: 0.4008 - acc: 0.8386    \n",
      "Epoch 5/10\n",
      "52976/52976 [==============================] - 29s - loss: 0.3981 - acc: 0.8387    \n",
      "Epoch 6/10\n",
      "52976/52976 [==============================] - 29s - loss: 0.3960 - acc: 0.8392    \n",
      "Epoch 7/10\n",
      "52976/52976 [==============================] - 29s - loss: 0.3943 - acc: 0.8400    \n",
      "Epoch 8/10\n",
      "52976/52976 [==============================] - 28s - loss: 0.3930 - acc: 0.8405    \n",
      "Epoch 9/10\n",
      "52976/52976 [==============================] - 28s - loss: 0.3919 - acc: 0.8410    \n",
      "Epoch 10/10\n",
      "52976/52976 [==============================] - 28s - loss: 0.3910 - acc: 0.8413    \n"
     ]
    }
   ],
   "source": [
    "# we need to create separate sequential models for each embedding\n",
    "import tensorflow as tf\n",
    "with tf.device('/GPU:0'):\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        # needs to be commented better, Eric!\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_branch_outputs)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False,name='numeric_data'))\n",
    "    x = Dense(units=20, activation='relu')(all_inputs[-1])\n",
    "    all_branch_outputs.append( x )\n",
    "\n",
    "    # merge the branches together\n",
    "    deep_branch = concatenate(all_branch_outputs)\n",
    "    deep_branch = Dense(units=50,activation='relu')(deep_branch)\n",
    "    deep_branch = Dense(units=10,activation='relu')(deep_branch)\n",
    "\n",
    "    final_branch = concatenate([wide_branch, deep_branch])\n",
    "    final_branch = Dense(units=1,activation='sigmoid')(final_branch)\n",
    "\n",
    "    model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "    model.compile(optimizer='adagrad',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_ints_train+ [X_train_num],\n",
    "            y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10770   203]\n",
      " [ 2030   242]] 0.83140807852\n"
     ]
    }
   ],
   "source": [
    "yhat = np.round(model.predict(X_ints_test + [X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\ovall\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2cabf02ce23a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ovall\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ovall\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     28\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
